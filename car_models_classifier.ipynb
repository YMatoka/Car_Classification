{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center> Classificateur de Modèles de voitures</center></h1>\n",
    " <img src=\"logo/image.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XlXkQ6qx_Xay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in c:\\users\\yannm\\anaconda3\\lib\\site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import os\n",
    "\n",
    "# Module de gestion du GPU\n",
    "!pip install GPUtil\n",
    "from numba import cuda\n",
    "from GPUtil import showUtilization as gpu_usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYdee71UJDSF"
   },
   "source": [
    "# **ETAPES** <p>\n",
    "Etape 0: Libération du cache de la carte graphique <p>\n",
    "Etape 1: Chargement des Datasets <p>\n",
    "Etape 2: Transformation des Datasets<p>\n",
    "Etape 3: Creation du Modele <p>\n",
    "Etape 4: Entrainement du Modele<p>\n",
    "Etape 5: Sauvegarde du Modele <p>\n",
    "Etape 6: Chargement du Modele <p>\n",
    "Etape 7: Predicition de l'Image <p>\n",
    "Etape 8: Affichage du Résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 0: Libération du cache de la carte graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  8% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% |  9% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "    \n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T7noSJhJUFr"
   },
   "source": [
    "## Etape 1: Chargement des Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74CbnuuJAx4Y"
   },
   "outputs": [],
   "source": [
    "data_dir = 'car_data/'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLysmbnmJemX"
   },
   "source": [
    "## Etape 2: Transformation des Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOqT-9GXA8F_"
   },
   "outputs": [],
   "source": [
    "#construction du modele du dataset d'entrainement\n",
    "train_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "#construction du modele du dataset de test\n",
    "test_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#construction du modele du dataset de alidation\n",
    "validation_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Chargement des datasets avec la methode ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(data_dir + '/valid', transform=validation_transforms)\n",
    "\n",
    "\n",
    "# Utilisation des Datasets d'images et création des models de transformation\n",
    "# Shuffle est a \"True\", ce qui signifie que l'odre des images n'affecte pas la création des modeles\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M265WLOdJ3xV"
   },
   "source": [
    "## Etape 3: Creation du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1emIi-zkXNz1",
    "outputId": "2a93d3d5-0c02-42c9-b596-667df7cb2327"
   },
   "outputs": [],
   "source": [
    "#model = models.densenet121(pretrained=True)\n",
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZcqibDULVbil",
    "outputId": "a4ecd4de-6a83-4c43-b141-e63791e084a2"
   },
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 196)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZQGN3U1tWu0"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1j802WQKhRa"
   },
   "source": [
    "## Etape 4: Entrainement du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7OXITrCGu5J"
   },
   "outputs": [],
   "source": [
    "# Fonction de validation du Modele\n",
    "def validation(model, validloader, criterion):\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # change model to work with cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Iterate over data from validloader\n",
    "    for ii, (images, labels) in enumerate(validloader):\n",
    "    \n",
    "        # Change images and labels to work with cuda\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass image though model for prediction\n",
    "        output = model.forward(images)\n",
    "        # Calculate loss\n",
    "        valid_loss += criterion(output, labels).item()\n",
    "        # Calculate probability\n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "eBpYU-KpuyFq",
    "outputId": "3f37ee6f-571b-4d84-9efa-9b88a9505692"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 6.00 GiB total capacity; 4.76 GiB already allocated; 0 bytes free; 4.91 GiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FF9F1C975A200007FF9F1C97540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FF9E9D59BB600007FF9E9D59B40 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FF9E9D6064600007FF9E9D5F320 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FF9E9D607EA00007FF9E9D5F320 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FF9E9D5504900007FF9E9D54E60 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FF980231FE100007FF980231EA0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FF980348E5E00007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF98034460500007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF978341A3A00007FF97832D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FF97834000500007FF97832D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FF9784118A000007FF978408FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FF9784228DC00007FF978422850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FF9781EC91400007FF9781EC6E0 torch_cpu.dll!at::TensorIterator::allocate_outputs [<unknown file> @ <unknown line number>]\n00007FF9781ED1E600007FF9781ED140 torch_cpu.dll!at::TensorIterator::build [<unknown file> @ <unknown line number>]\n00007FF9781EC25D00007FF9781EC1A0 torch_cpu.dll!at::TensorIterator::TensorIterator [<unknown file> @ <unknown line number>]\n00007FF9781ED0C600007FF9781ED000 torch_cpu.dll!at::TensorIterator::binary_op [<unknown file> @ <unknown line number>]\n00007FF97805787000007FF9780577E0 torch_cpu.dll!at::native::div [<unknown file> @ <unknown line number>]\n00007FF9803486DF00007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF980341E8200007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF97840D94900007FF978408FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FF97851610700007FF9785160B0 torch_cpu.dll!at::Tensor::div [<unknown file> @ <unknown line number>]\n00007FF978057A6A00007FF9780579F0 torch_cpu.dll!at::native::div [<unknown file> @ <unknown line number>]\n00007FF9784E647200007FF97846D060 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FF977FA204C00007FF977F96470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FF97842030F00007FF978420250 torch_cpu.dll!at::div [<unknown file> @ <unknown line number>]\n00007FF979790E1900007FF9796AE010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FF977FA204C00007FF977F96470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FF97851622F00007FF978516170 torch_cpu.dll!at::Tensor::div [<unknown file> @ <unknown line number>]\n00007FF97960DE3B00007FF97960DBC0 torch_cpu.dll!torch::autograd::generated::MeanBackward1::apply [<unknown file> @ <unknown line number>]\n00007FF9795E7E9100007FF9795E7B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FF979B4F9BA00007FF979B4F300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FF979B503AD00007FF979B4FFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FF979B54FE200007FF979B54CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FF979B54C4100007FF979B54BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FF9B25E08A700007FF9B25B9F30 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FF979B4BF1400007FF979B4B780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFA32991BB200007FFA32991B20 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFA33CF703400007FFA33CF7020 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFA351A265100007FFA351A2630 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6b3a870353ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 6.00 GiB total capacity; 4.76 GiB already allocated; 0 bytes free; 4.91 GiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FF9F1C975A200007FF9F1C97540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FF9E9D59BB600007FF9E9D59B40 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FF9E9D6064600007FF9E9D5F320 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FF9E9D607EA00007FF9E9D5F320 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FF9E9D5504900007FF9E9D54E60 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FF980231FE100007FF980231EA0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FF980348E5E00007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF98034460500007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF978341A3A00007FF97832D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FF97834000500007FF97832D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FF9784118A000007FF978408FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FF9784228DC00007FF978422850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FF9781EC91400007FF9781EC6E0 torch_cpu.dll!at::TensorIterator::allocate_outputs [<unknown file> @ <unknown line number>]\n00007FF9781ED1E600007FF9781ED140 torch_cpu.dll!at::TensorIterator::build [<unknown file> @ <unknown line number>]\n00007FF9781EC25D00007FF9781EC1A0 torch_cpu.dll!at::TensorIterator::TensorIterator [<unknown file> @ <unknown line number>]\n00007FF9781ED0C600007FF9781ED000 torch_cpu.dll!at::TensorIterator::binary_op [<unknown file> @ <unknown line number>]\n00007FF97805787000007FF9780577E0 torch_cpu.dll!at::native::div [<unknown file> @ <unknown line number>]\n00007FF9803486DF00007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF980341E8200007FF9802EE400 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FF97840D94900007FF978408FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FF97851610700007FF9785160B0 torch_cpu.dll!at::Tensor::div [<unknown file> @ <unknown line number>]\n00007FF978057A6A00007FF9780579F0 torch_cpu.dll!at::native::div [<unknown file> @ <unknown line number>]\n00007FF9784E647200007FF97846D060 torch_cpu.dll!at::zeros_out [<unknown file> @ <unknown line number>]\n00007FF977FA204C00007FF977F96470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FF97842030F00007FF978420250 torch_cpu.dll!at::div [<unknown file> @ <unknown line number>]\n00007FF979790E1900007FF9796AE010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FF977FA204C00007FF977F96470 torch_cpu.dll!torch::nn::functional::BatchNormFuncOptions::~BatchNormFuncOptions [<unknown file> @ <unknown line number>]\n00007FF97851622F00007FF978516170 torch_cpu.dll!at::Tensor::div [<unknown file> @ <unknown line number>]\n00007FF97960DE3B00007FF97960DBC0 torch_cpu.dll!torch::autograd::generated::MeanBackward1::apply [<unknown file> @ <unknown line number>]\n00007FF9795E7E9100007FF9795E7B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FF979B4F9BA00007FF979B4F300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FF979B503AD00007FF979B4FFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FF979B54FE200007FF979B54CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FF979B54C4100007FF979B54BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FF9B25E08A700007FF9B25B9F30 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FF979B4BF1400007FF979B4B780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFA32991BB200007FFA32991B20 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFA33CF703400007FFA33CF7020 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFA351A265100007FFA351A2630 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 # Nombre de passage à travers le datasets\n",
    "steps = 0\n",
    "print_every = 40\n",
    "\n",
    "# Passage au mode GPU\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    #Iteration à travers les données pour effectuer les étapes d'entrainement\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # Mise à zero des paramètres gradiants\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward >> Calcul de la prédiction pour la couche suivante\n",
    "        # Backward >> Calcul du gradient pour la couche précédente\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Réalisation des étapes de validations\n",
    "        if steps % print_every == 0:\n",
    "            \n",
    "            # Paramétrage du mode evaluation pendant la validation\n",
    "            model.eval()\n",
    "            \n",
    "            # Les gradients sont mis à zeros lorsqu'ils ne sont plus en entraienements\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
    "            \n",
    "            print(f\"No. epochs: {e+1}, \\\n",
    "            Training Loss: {round(running_loss/print_every,3)} \\\n",
    "            Valid Loss: {round(valid_loss/len(validloader),3)} \\\n",
    "            Valid Accuracy: {round(float(accuracy/len(validloader)),3)}\")\n",
    "            \n",
    "            # Retour à l'entrainement du modele\n",
    "            model.train()\n",
    "            lrscheduler.step(accuracy * 100)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cXyFWRKJIaqU",
    "outputId": "9c721d83-bc50-4a6d-bbc1-5cc8d5fc8c5d"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        # Get probabilities\n",
    "        outputs = model(images)\n",
    "        # Turn probabilities into predictions\n",
    "        _, predicted_outcome = torch.max(outputs.data, 1)\n",
    "        # Total number of images\n",
    "        total += labels.size(0)\n",
    "        # Count number of cases in which predictions are correct\n",
    "        correct += (predicted_outcome == labels).sum().item()\n",
    "\n",
    "print(f\"Test de Précision du Modele: {round(100 * correct / total,3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dekV68M3Kufx"
   },
   "source": [
    "##  Etape 5: Sauvegarde du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vcTL2RZBdDk"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde des paramètres du modèle\n",
    "checkpoint = {'state_dict': model.state_dict(),\n",
    "              'model': model.fc,\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'opt_state': optimizer.state_dict,\n",
    "              'num_epochs': epochs}\n",
    "\n",
    "torch.save(checkpoint, data_dir + 'sauvegarde.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PM9BMpgxK5pe"
   },
   "source": [
    "## Etape 6: Chargement du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3uxYcS4Lo0D"
   },
   "outputs": [],
   "source": [
    "# Fonction qui charge les données de sauvegarde et reconstruit le modele\n",
    "def load_checkpoint(filepath):\n",
    "\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dbACQoOmN1Dp",
    "outputId": "b913c74c-7624-4c50-80d6-b6aa105cd5f0"
   },
   "outputs": [],
   "source": [
    "# Chargement du modele\n",
    "model = load_checkpoint(data_dir + 'sauvegarde.pth')\n",
    "# Vérification du nombre de sorties du classisficateur\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxpeelnTkWLg"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFnIGydILDh8"
   },
   "source": [
    "## Etape 7: Predicition de l'Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4-5e6f-XzPW"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "\n",
    "    # Traitemement d'une image avec le modele Pytorch\n",
    "    \n",
    "    # Convertion de l'image en format PIL image \n",
    "    pil_im = Image.open(f'{image}' + '.jpg')\n",
    "\n",
    "    # Cosntruction de la trasnformation d'image\n",
    "    transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                    #transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                         [0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    # Trasnformation de l'image pour l'utiliser dans le réseau neural\n",
    "    pil_tfd = transform(pil_im)\n",
    "    \n",
    "    # Convertion en tableau Numpy\n",
    "    array_im_tfd = np.array(pil_tfd)\n",
    "    \n",
    "    return array_im_tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rH4Elba-CNnD"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors suppose que le canal de couleur est la première dimension\n",
    "    # Cependant matplotlib suppose que c'est la troisième dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Annulation du prétraitement\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # L'Image à besoin d'etre coupé entre 0 et 1 pour etre correctement affiché \n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "1t3KpW8MCdD1",
    "outputId": "5b16dd26-b5ac-4138-9321-32ec8d47accf"
   },
   "outputs": [],
   "source": [
    "imshow(process_image(data_dir + 'bmw 3 2019'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3tTW5LeC5UJ"
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5): \n",
    "    # Implémentation du code pour prédire une classe à aprtir d'une image\n",
    "    \n",
    "    # Chargement du modele\n",
    "    loaded_model = load_checkpoint(model).cpu()\n",
    "    # Pré traitementdu modele\n",
    "    img = process_image(image_path)\n",
    "    # Convertion du torch tensor en image\n",
    "    img_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "    # Adding dimension to image to comply with (B x C x W x H) input of model\n",
    "    img_add_dim = img_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Paramétrage du model du mode évaluation et mise à zero des gradients\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Exécution de l'image à travers du réseau neural\n",
    "        output = loaded_model.forward(img_add_dim)\n",
    "        \n",
    "    #conf, predicted = torch.max(output.data, 1)   \n",
    "    probs_top = output.topk(topk)[0]\n",
    "    predicted_top = output.topk(topk)[1]\n",
    "    \n",
    "    # Convertion des probalités et des résultats en listes\n",
    "    conf = np.array(probs_top)[0]\n",
    "    predicted = np.array(predicted_top)[0]\n",
    "        \n",
    "    #return probs_top_list, index_top_list\n",
    "    return conf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mnMLifs1xkFH",
    "outputId": "43f660ac-f595-4844-c523-2b279ec0b018"
   },
   "outputs": [],
   "source": [
    "# Rattache les indices de classes à leur noms\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "classes, c_to_idx = find_classes(data_dir+\"train\")\n",
    "\n",
    "print(classes, c_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vArJuuBLMorV"
   },
   "source": [
    "## Etape 8: Affichage du Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zB2xQXIx3ONA",
    "outputId": "d04fb87c-3be4-42cb-8d3e-94c4d8ddc856"
   },
   "outputs": [],
   "source": [
    "model_path = '/content/drive/My Drive/Colab Notebooks/my_checkpoint1.pth'\n",
    "image_path = data_dir + 'bmw 3 2010'\n",
    "\n",
    "\n",
    "conf1, predicted1 = predict(image_path, model_path, topk=5)\n",
    "\n",
    "print(conf1)\n",
    "print(classes[predicted1[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tztcZ6fQV1O7"
   },
   "outputs": [],
   "source": [
    "# Test de la fonction de prédiction\n",
    "\n",
    "# Les Inputs sont les chemins du modele suavegardé et de l'image\n",
    "model_path =  data_dir + 'sauvegarde.pth'\n",
    "carname = 'Hyundai Veloster Hatchback 2012'\n",
    "image_path = data_dir + carname\n",
    "\n",
    "\n",
    "conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "# Convertion des classes en noms\n",
    "names = []\n",
    "for i in range(5):\n",
    "  \n",
    "    names += [classes[predicted1[i]]]\n",
    "\n",
    "# Creation de limage PIL\n",
    "image = Image.open(image_path+'.jpg')\n",
    "\n",
    "#Affichage de l'image test et des probabilités\n",
    "f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(carname)\n",
    "\n",
    "y_names = np.arange(len(names))\n",
    "ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "ax[1].set_yticks(y_names)\n",
    "ax[1].set_yticklabels(names)\n",
    "ax[1].invert_yaxis() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w-rrr1Ey-5j"
   },
   "outputs": [],
   "source": [
    "def plot_solution(cardir, model):\n",
    " # Test de la fonction de prédiction\n",
    "\n",
    "  # Les Inputs sont les chemins du modele suavegardé et de l'image\n",
    "  model_path = data_dir + 'sauvegarde.pth'\n",
    "  image_path = test_dir + cardir\n",
    "  carname = cardir.split('/')[1]\n",
    "\n",
    "  conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "  # Convertion des classes en noms\n",
    "  names = []\n",
    "  for i in range(5):\n",
    "  \n",
    "      names += [classes[predicted1[i]]]\n",
    "\n",
    "\n",
    "  # Creation de limage PIL\n",
    "  image = Image.open(image_path+'.jpg')\n",
    "\n",
    "  #Affichage de l'image test et des probabilités\n",
    "  f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "  ax[0].imshow(image)\n",
    "  ax[0].set_title(carname)\n",
    "\n",
    "  y_names = np.arange(len(names))\n",
    "  ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "  ax[1].set_yticks(y_names)\n",
    "  ax[1].set_yticklabels(names)\n",
    "  ax[1].invert_yaxis() \n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "3oFutf8v5B4k",
    "outputId": "57557d53-9d08-42d0-b750-922a312b69c1"
   },
   "outputs": [],
   "source": [
    "cardir='/Mercedes-Benz S-Class Sedan 2012/06543'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "LjKmsvWD21Z5",
    "outputId": "e4b8e62e-5008-4661-dd65-bc17d0a10145"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW 3 Series Sedan 2012/06582'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "UX117BuN6ySN",
    "outputId": "7a633f1c-c7b9-4361-d608-4ebad81b2af6"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW 3 Series Sedan 2012/06544'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "mV5KWYT37U77",
    "outputId": "8847ba5c-8b21-40b2-a699-10d6ce519e09"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW M5 Sedan 2010/03529'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "kkGdcQis7gIs",
    "outputId": "b1c948b4-c5c1-4ddc-bbca-62302c768b51"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW X6 SUV 2012/02891'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "g_DkjlIQ7tqz",
    "outputId": "538b2dd1-29e7-41aa-c6ac-88cfd11a46e8"
   },
   "outputs": [],
   "source": [
    "cardir='/BMW X5 SUV 2007/03310'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "id": "8jaUcCQ-73Ga",
    "outputId": "1cbf49cf-55c2-4fac-e878-322370440830"
   },
   "outputs": [],
   "source": [
    "cardir='/Hyundai Veloster Hatchback 2012/06652'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "cATjCLma7_ua",
    "outputId": "450db199-94a1-4eff-80cb-a8e01467b755"
   },
   "outputs": [],
   "source": [
    "cardir='/Volkswagen Golf Hatchback 2012/06875'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "1G_qZ0Sa8Jdh",
    "outputId": "eb46c5b4-fa42-4982-84e0-086e6f0bd4e4"
   },
   "outputs": [],
   "source": [
    "cardir='/Hyundai Tucson SUV 2012/07220'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpOpoVC68Rpa"
   },
   "outputs": [],
   "source": [
    "imageFileName = input(\"Entrer l'URL de l'image la voiture\")\n",
    "plot_solution(imageFileName, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cars model classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
